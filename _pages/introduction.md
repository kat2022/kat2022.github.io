---
layout: page
title: Introduction
permalink: /introduction/
---

#### 赛题名称
<p> 预训练模型知识量度量</p>


#### 赛题背景
<p> 近年来，以BERT为代表的预训练模型在各项NLP任务中取得了重大突破。相关研究表明，预训练模型不仅可以学习通用语言表示，还可以学习结构化的知识，包括常识知识和事实知识。以BERT为例，可以通过完形填空任务记忆结构化的事实知识，如“Einstein was born in the country [Mask]”即在捕捉（Einstein, born-in, Germany）的三元组信息。模型将知识编码进上亿参数中，使一系列的下游任务，如常识（视觉）问题解答、信息检索，可以从预先捕捉的事实知识和常识知识中受益。</p>
<p> 为了更深入地理解预训练模型，我们构建数据集来系统地评估模型的知识含量，不仅考察模型预训练阶段所编码的知识量，同时考察模型是否具备推理能力。为此，我们构造了来自不同领域（历史、军事、医学等）、不同类型（事实知识、常识知识）、不同难度（单条知识、多条知识组合）的问题，把对模型知识量的测评，转换为相应的完型填空问题。当模型能成功填充[MASK]标识符时，则说明该模型掌握了相关知识。</p>
<p> 我们希望通过考察模型的知识量，驱动业界对于模型知识表示的研究，实现预训练模型向下游任务更有效的知识转移。 本次预训练模型的知识量评估侧重于考察模型的记忆能力，特别是在few-shot或zero-shot情况下的记忆和能力和多知识组合能力，后期会加入更多的推理类问题，以及考察模型本身的泛化能力。</p>


#### 赛题任务
<p> 本赛题构建了完型填空形式的英文测评数据集，评估预训练模型在9个领域、两大知识类型（事实知识、常识知识）、不同难度任务上的知识含量。</p>
